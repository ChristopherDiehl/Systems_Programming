{"list" : [
	{"a"[
		{"jsonWriter.c" :3}
	]},
	{"a"[
		{"fileTokenizer.c" :15},
		{"cabla.txt" :1}
	]},
	{"a"[
		{"bacon0.txt" :1}
	]},
	{"ad"[
		{"bacon1.txt" :6}
	]},
	{"add"[
		{"test1.c" :1},
		{"jsonWriter.c" :1}
	]},
	{"addtolist"[
		{"test1.c" :1}
	]},
	{"adipisicing"[
		{"bacon1.txt" :7},
		{"bacon0.txt" :2}
	]},
	{"after"[
		{"fileTokenizer.c" :2}
	]},
	{"alcatra"[
		{"bacon1.txt" :2}
	]},
	{"aliqua"[
		{"bacon1.txt" :2}
	]},
	{"aliquip"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :3}
	]},
	{"all"[
		{"fileTokenizer.c" :1}
	]},
	{"allocate"[
		{"fileTokenizer.c" :1}
	]},
	{"allocated"[
		{"fileTokenizer.c" :2}
	]},
	{"am"[
		{"bacon0.txt" :1}
	]},
	{"amet"[
		{"bacon1.txt" :1},
		{"bacon0.txt" :1}
	]},
	{"and"[
		{"fileTokenizer.c" :2},
		{"cabla.txt" :1}
	]},
	{"andouille"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :2}
	]},
	{"anim"[
		{"bacon1.txt" :9},
		{"bacon0.txt" :1}
	]},
	{"another"[
		{"fileTokenizer.c" :1}
	]},
	{"any"[
		{"jsonWriter.c" :1}
	]},
	{"appends"[
		{"jsonWriter.c" :1}
	]},
	{"are"[
		{"fileTokenizer.c" :1}
	]},
	{"argc"[
		{"test1.c" :2}
	]},
	{"args"[
		{"test1.c" :1}
	]},
	{"arguments"[
		{"fileTokenizer.c" :1}
	]},
	{"argv"[
		{"test1.c" :4}
	]},
	{"as"[
		{"fileTokenizer.c" :3}
	]},
	{"asf"[
		{"fileTokenizer.c" :1}
	]},
	{"aute"[
		{"bacon1.txt" :3}
	]},
	{"baa"[
		{"jsonWriter.c" :2}
	]},
	{"bacon"[
		{"cabla.txt" :1}
	]},
	{"bacon"[
		{"bacon1.txt" :4},
		{"bacon0.txt" :2}
	]},
	{"ball"[
		{"bacon1.txt" :3}
	]},
	{"be"[
		{"fileTokenizer.c" :1}
	]},
	{"beef"[
		{"bacon1.txt" :8}
	]},
	{"been"[
		{"jsonWriter.c" :1}
	]},
	{"begins"[
		{"fileTokenizer.c" :1}
	]},
	{"being"[
		{"fileTokenizer.c" :1}
	]},
	{"belly"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"besides"[
		{"fileTokenizer.c" :1}
	]},
	{"biltong"[
		{"bacon1.txt" :4}
	]},
	{"bone"[
		{"bacon1.txt" :1}
	]},
	{"boudin"[
		{"bacon1.txt" :4},
		{"bacon0.txt" :1}
	]},
	{"br"[
		{"bacon0.txt" :1}
	]},
	{"break"[
		{"test1.c" :1},
		{"jsonWriter.c" :1}
	]},
	{"break"[
		{"fileTokenizer.c" :4}
	]},
	{"bresaola"[
		{"bacon1.txt" :4}
	]},
	{"brisket"[
		{"bacon1.txt" :5}
	]},
	{"bro"[
		{"cabla.txt" :1}
	]},
	{"bs"[
		{"bacon0.txt" :1}
	]},
	{"buffer"[
		{"fileTokenizer.c" :5}
	]},
	{"by"[
		{"jsonWriter.c" :2}
	]},
	{"by"[
		{"fileTokenizer.c" :1}
	]},
	{"by"[
		{"asst3hints.txt" :1}
	]},
	{"c"[
		{"fileTokenizer.c" :1}
	]},
	{"call"[
		{"jsonWriter.c" :1}
	]},
	{"caller"[
		{"fileTokenizer.c" :1}
	]},
	{"calling"[
		{"jsonWriter.c" :1}
	]},
	{"calloc"[
		{"jsonWriter.c" :3}
	]},
	{"capicola"[
		{"bacon1.txt" :1},
		{"bacon0.txt" :1}
	]},
	{"case"[
		{"fileTokenizer.c" :3}
	]},
	{"change"[
		{"fileTokenizer.c" :2}
	]},
	{"changes"[
		{"jsonWriter.c" :1}
	]},
	{"char"[
		{"test1.c" :2},
		{"jsonWriter.c" :17}
	]},
	{"char"[
		{"fileTokenizer.c" :19}
	]},
	{"char"[
		{"asst3hints.txt" :1}
	]},
	{"character"[
		{"fileTokenizer.c" :4}
	]},
	{"check"[
		{"test1.c" :1},
		{"fileTokenizer.c" :1}
	]},
	{"chicken"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :1}
	]},
	{"chop"[
		{"bacon1.txt" :4},
		{"bacon0.txt" :1}
	]},
	{"chuck"[
		{"bacon1.txt" :4}
	]},
	{"cillum"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :1}
	]},
	{"close"[
		{"jsonWriter.c" :1}
	]},
	{"comma"[
		{"jsonWriter.c" :3}
	]},
	{"commodo"[
		{"bacon1.txt" :1}
	]},
	{"consectetur"[
		{"bacon1.txt" :7},
		{"bacon0.txt" :1}
	]},
	{"consequat"[
		{"bacon1.txt" :5}
	]},
	{"containing"[
		{"fileTokenizer.c" :1}
	]},
	{"continue"[
		{"fileTokenizer.c" :1}
	]},
	{"copy"[
		{"fileTokenizer.c" :1}
	]},
	{"corned"[
		{"bacon1.txt" :1}
	]},
	{"correspond"[
		{"cabla.txt" :1}
	]},
	{"cow"[
		{"bacon1.txt" :4}
	]},
	{"creates"[
		{"fileTokenizer.c" :1}
	]},
	{"culpa"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :3}
	]},
	{"cupidatat"[
		{"bacon1.txt" :6}
	]},
	{"cupim"[
		{"bacon1.txt" :1},
		{"bacon0.txt" :1}
	]},
	{"d"[
		{"test1.c" :1},
		{"jsonWriter.c" :1}
	]},
	{"default"[
		{"fileTokenizer.c" :1}
	]},
	{"delete"[
		{"jsonWriter.c" :1}
	]},
	{"deleted"[
		{"asst3hints.txt" :1}
	]},
	{"delimited"[
		{"fileTokenizer.c" :1}
	]},
	{"dependent"[
		{"fileTokenizer.c" :1}
	]},
	{"deserunt"[
		{"bacon1.txt" :4}
	]},
	{"dest"[
		{"fileTokenizer.c" :3}
	]},
	{"destroyed"[
		{"fileTokenizer.c" :1}
	]},
	{"destroyjson"[
		{"jsonWriter.c" :1}
	]},
	{"destroys"[
		{"fileTokenizer.c" :1}
	]},
	{"digit"[
		{"fileTokenizer.c" :1}
	]},
	{"directories"[
		{"asst3hints.txt" :1}
	]},
	{"dirent"[
		{"asst3hints.txt" :1}
	]},
	{"dirfd"[
		{"asst3hints.txt" :1}
	]},
	{"disregard"[
		{"fileTokenizer.c" :2}
	]},
	{"do"[
		{"jsonWriter.c" :1}
	]},
	{"do"[
		{"bacon1.txt" :1},
		{"bacon0.txt" :1}
	]},
	{"dolor"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"dolore"[
		{"bacon1.txt" :17},
		{"bacon0.txt" :1}
	]},
	{"doner"[
		{"bacon1.txt" :3},
		{"bacon0.txt" :1}
	]},
	{"dont"[
		{"jsonWriter.c" :1}
	]},
	{"drumstick"[
		{"bacon1.txt" :3},
		{"bacon0.txt" :1}
	]},
	{"duis"[
		{"bacon1.txt" :4},
		{"bacon0.txt" :1}
	]},
	{"during"[
		{"fileTokenizer.c" :2}
	]},
	{"dynamically"[
		{"fileTokenizer.c" :2}
	]},
	{"ea"[
		{"bacon1.txt" :6},
		{"bacon0.txt" :1}
	]},
	{"efficiency"[
		{"fileTokenizer.c" :1}
	]},
	{"eiusmod"[
		{"bacon1.txt" :5}
	]},
	{"elit"[
		{"bacon1.txt" :6},
		{"bacon0.txt" :1}
	]},
	{"else"[
		{"jsonWriter.c" :3}
	]},
	{"else"[
		{"fileTokenizer.c" :5}
	]},
	{"endfilerecord"[
		{"jsonWriter.c" :6}
	]},
	{"enim"[
		{"bacon1.txt" :8},
		{"bacon0.txt" :1}
	]},
	{"enter"[
		{"test1.c" :1},
		{"jsonWriter.c" :1}
	]},
	{"entry"[
		{"jsonWriter.c" :19}
	]},
	{"error"[
		{"jsonWriter.c" :1}
	]},
	{"esse"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :1}
	]},
	{"est"[
		{"bacon1.txt" :2}
	]},
	{"et"[
		{"bacon1.txt" :3}
	]},
	{"eu"[
		{"bacon1.txt" :5}
	]},
	{"ex"[
		{"bacon1.txt" :3}
	]},
	{"excepteur"[
		{"bacon1.txt" :1}
	]},
	{"exercitation"[
		{"bacon1.txt" :7}
	]},
	{"expect"[
		{"jsonWriter.c" :1}
	]},
	{"extra"[
		{"jsonWriter.c" :3}
	]},
	{"failed"[
		{"fileTokenizer.c" :1}
	]},
	{"fatback"[
		{"bacon1.txt" :4}
	]},
	{"fclose"[
		{"jsonWriter.c" :1}
	]},
	{"fclose"[
		{"fileTokenizer.c" :1}
	]},
	{"file"[
		{"jsonWriter.c" :19}
	]},
	{"file"[
		{"fileTokenizer.c" :10},
		{"cabla.txt" :1}
	]},
	{"file"[
		{"bacon0.txt" :1}
	]},
	{"filename"[
		{"jsonWriter.c" :17}
	]},
	{"filename"[
		{"fileTokenizer.c" :6}
	]},
	{"files"[
		{"asst3hints.txt" :1}
	]},
	{"filesize"[
		{"jsonWriter.c" :6}
	]},
	{"filet"[
		{"bacon1.txt" :4},
		{"bacon0.txt" :2}
	]},
	{"filetokenizer"[
		{"test1.c" :1},
		{"fileTokenizer.c" :1}
	]},
	{"fill"[
		{"fileTokenizer.c" :1}
	]},
	{"find"[
		{"cabla.txt" :1}
	]},
	{"find"[
		{"asst3hints.txt" :3}
	]},
	{"flank"[
		{"bacon1.txt" :7}
	]},
	{"flist"[
		{"test1.c" :4},
		{"jsonWriter.c" :5}
	]},
	{"fopen"[
		{"jsonWriter.c" :1}
	]},
	{"fopen"[
		{"fileTokenizer.c" :1}
	]},
	{"for"[
		{"jsonWriter.c" :1}
	]},
	{"for"[
		{"fileTokenizer.c" :5}
	]},
	{"formats"[
		{"jsonWriter.c" :1}
	]},
	{"formattedtoken"[
		{"jsonWriter.c" :4}
	]},
	{"forward"[
		{"fileTokenizer.c" :1}
	]},
	{"frankfurter"[
		{"bacon1.txt" :6},
		{"bacon0.txt" :1}
	]},
	{"fread"[
		{"fileTokenizer.c" :1}
	]},
	{"free"[
		{"jsonWriter.c" :3}
	]},
	{"free"[
		{"fileTokenizer.c" :3}
	]},
	{"free"[
		{"asst3hints.txt" :2}
	]},
	{"freed"[
		{"fileTokenizer.c" :1}
	]},
	{"freeing"[
		{"fileTokenizer.c" :1}
	]},
	{"frees"[
		{"fileTokenizer.c" :1}
	]},
	{"freqsize"[
		{"jsonWriter.c" :7}
	]},
	{"frequency"[
		{"jsonWriter.c" :13}
	]},
	{"frequencylist"[
		{"test1.c" :2},
		{"jsonWriter.c" :1}
	]},
	{"from"[
		{"test1.c" :1},
		{"jsonWriter.c" :1}
	]},
	{"from"[
		{"fileTokenizer.c" :2}
	]},
	{"fugiat"[
		{"bacon1.txt" :2}
	]},
	{"function"[
		{"fileTokenizer.c" :3}
	]},
	{"functions"[
		{"fileTokenizer.c" :2}
	]},
	{"future"[
		{"fileTokenizer.c" :1}
	]},
	{"fwrite"[
		{"jsonWriter.c" :5}
	]},
	{"getfrequency"[
		{"jsonWriter.c" :2}
	]},
	{"getfrequency"[
		{"asst3hints.txt" :1}
	]},
	{"getfrequencylist"[
		{"test1.c" :1}
	]},
	{"getjsonrecord"[
		{"jsonWriter.c" :2}
	]},
	{"getjsontoken"[
		{"jsonWriter.c" :2}
	]},
	{"gettoken"[
		{"test1.c" :1},
		{"fileTokenizer.c" :1}
	]},
	{"given"[
		{"jsonWriter.c" :1}
	]},
	{"given"[
		{"fileTokenizer.c" :2}
	]},
	{"great"[
		{"cabla.txt" :2}
	]},
	{"ground"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"h"[
		{"test1.c" :2},
		{"jsonWriter.c" :1}
	]},
	{"h"[
		{"fileTokenizer.c" :1}
	]},
	{"ham"[
		{"bacon1.txt" :8},
		{"bacon0.txt" :1}
	]},
	{"hamburger"[
		{"bacon1.txt" :1},
		{"bacon0.txt" :1}
	]},
	{"handles"[
		{"jsonWriter.c" :1}
	]},
	{"handles"[
		{"fileTokenizer.c" :1}
	]},
	{"has"[
		{"jsonWriter.c" :1}
	]},
	{"have"[
		{"jsonWriter.c" :1}
	]},
	{"help"[
		{"bacon0.txt" :1}
	]},
	{"helper"[
		{"fileTokenizer.c" :1}
	]},
	{"hock"[
		{"bacon1.txt" :4}
	]},
	{"i"[
		{"fileTokenizer.c" :7},
		{"bacon0.txt" :1}
	]},
	{"id"[
		{"bacon1.txt" :5}
	]},
	{"ie"[
		{"fileTokenizer.c" :1}
	]},
	{"if"[
		{"test1.c" :3},
		{"jsonWriter.c" :9}
	]},
	{"if"[
		{"fileTokenizer.c" :18}
	]},
	{"immutable"[
		{"fileTokenizer.c" :1}
	]},
	{"implementation"[
		{"fileTokenizer.c" :1}
	]},
	{"in"[
		{"jsonWriter.c" :1}
	]},
	{"in"[
		{"fileTokenizer.c" :3},
		{"bacon1.txt" :11},
		{"bacon0.txt" :4}
	]},
	{"incididunt"[
		{"bacon1.txt" :4}
	]},
	{"include"[
		{"test1.c" :2},
		{"jsonWriter.c" :1}
	]},
	{"include"[
		{"fileTokenizer.c" :1}
	]},
	{"increase"[
		{"fileTokenizer.c" :1}
	]},
	{"indef"[
		{"fileTokenizer.c" :6}
	]},
	{"input"[
		{"test1.c" :1},
		{"jsonWriter.c" :1}
	]},
	{"int"[
		{"test1.c" :2},
		{"jsonWriter.c" :9}
	]},
	{"int"[
		{"fileTokenizer.c" :9}
	]},
	{"into"[
		{"jsonWriter.c" :1}
	]},
	{"invalid"[
		{"fileTokenizer.c" :1}
	]},
	{"ipsum"[
		{"bacon1.txt" :3},
		{"bacon0.txt" :1}
	]},
	{"irure"[
		{"bacon1.txt" :6}
	]},
	{"is"[
		{"fileTokenizer.c" :9},
		{"cabla.txt" :3}
	]},
	{"is"[
		{"bacon0.txt" :1}
	]},
	{"isalpha"[
		{"fileTokenizer.c" :1}
	]},
	{"isdigit"[
		{"fileTokenizer.c" :3}
	]},
	{"isempty"[
		{"jsonWriter.c" :2}
	]},
	{"isspace"[
		{"fileTokenizer.c" :2}
	]},
	{"istrailing"[
		{"jsonWriter.c" :1}
	]},
	{"isword"[
		{"fileTokenizer.c" :3}
	]},
	{"it"[
		{"jsonWriter.c" :1}
	]},
	{"it"[
		{"fileTokenizer.c" :7}
	]},
	{"it"[
		{"asst3hints.txt" :1}
	]},
	{"item"[
		{"fileTokenizer.c" :1}
	]},
	{"jerky"[
		{"bacon1.txt" :7},
		{"bacon0.txt" :1}
	]},
	{"jowl"[
		{"bacon1.txt" :2}
	]},
	{"json"[
		{"jsonWriter.c" :2}
	]},
	{"json"[
		{"asst3hints.txt" :2}
	]},
	{"jsonwrite"[
		{"jsonWriter.c" :2}
	]},
	{"jsonwriter"[
		{"jsonWriter.c" :1}
	]},
	{"keep"[
		{"asst3hints.txt" :1}
	]},
	{"kevin"[
		{"bacon1.txt" :2}
	]},
	{"kielbasa"[
		{"bacon1.txt" :1},
		{"bacon0.txt" :1}
	]},
	{"kind"[
		{"fileTokenizer.c" :1}
	]},
	{"labore"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"laboris"[
		{"bacon1.txt" :3}
	]},
	{"laborum"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :1}
	]},
	{"landjaeger"[
		{"bacon1.txt" :3},
		{"bacon0.txt" :1}
	]},
	{"last"[
		{"fileTokenizer.c" :1}
	]},
	{"later"[
		{"jsonWriter.c" :1}
	]},
	{"leberkas"[
		{"bacon1.txt" :1}
	]},
	{"len"[
		{"fileTokenizer.c" :3}
	]},
	{"length"[
		{"fileTokenizer.c" :6}
	]},
	{"list"[
		{"test1.c" :1},
		{"jsonWriter.c" :5}
	]},
	{"loin"[
		{"bacon1.txt" :3},
		{"bacon0.txt" :1}
	]},
	{"longer"[
		{"fileTokenizer.c" :1}
	]},
	{"loop"[
		{"fileTokenizer.c" :1}
	]},
	{"lorem"[
		{"bacon1.txt" :2}
	]},
	{"lowercase"[
		{"fileTokenizer.c" :1}
	]},
	{"m3"[
		{"bacon0.txt" :1}
	]},
	{"magna"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"main"[
		{"test1.c" :1},
		{"fileTokenizer.c" :1}
	]},
	{"make"[
		{"jsonWriter.c" :1}
	]},
	{"make"[
		{"fileTokenizer.c" :1}
	]},
	{"make"[
		{"asst3hints.txt" :1}
	]},
	{"malloc"[
		{"jsonWriter.c" :1}
	]},
	{"malloc"[
		{"fileTokenizer.c" :5}
	]},
	{"malloced"[
		{"fileTokenizer.c" :1}
	]},
	{"may"[
		{"fileTokenizer.c" :1}
	]},
	{"meatball"[
		{"bacon1.txt" :5}
	]},
	{"meatloaf"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :1}
	]},
	{"memory"[
		{"fileTokenizer.c" :1}
	]},
	{"mignon"[
		{"bacon1.txt" :4},
		{"bacon0.txt" :2}
	]},
	{"minim"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"mollit"[
		{"bacon1.txt" :7}
	]},
	{"n"[
		{"test1.c" :7},
		{"jsonWriter.c" :10}
	]},
	{"n"[
		{"fileTokenizer.c" :3}
	]},
	{"name"[
		{"fileTokenizer.c" :1}
	]},
	{"need"[
		{"fileTokenizer.c" :2}
	]},
	{"need"[
		{"asst3hints.txt" :2}
	]},
	{"needed"[
		{"fileTokenizer.c" :1}
	]},
	{"needs"[
		{"asst3hints.txt" :2}
	]},
	{"new"[
		{"fileTokenizer.c" :1}
	]},
	{"next"[
		{"fileTokenizer.c" :4}
	]},
	{"nisi"[
		{"bacon1.txt" :5}
	]},
	{"no"[
		{"fileTokenizer.c" :2}
	]},
	{"node"[
		{"jsonWriter.c" :1}
	]},
	{"nodes"[
		{"jsonWriter.c" :1}
	]},
	{"nodes"[
		{"cabla.txt" :1}
	]},
	{"non"[
		{"fileTokenizer.c" :1},
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"nostrud"[
		{"bacon1.txt" :11}
	]},
	{"not"[
		{"jsonWriter.c" :1}
	]},
	{"not"[
		{"fileTokenizer.c" :1}
	]},
	{"null"[
		{"fileTokenizer.c" :4}
	]},
	{"nulla"[
		{"bacon1.txt" :4}
	]},
	{"o"[
		{"jsonWriter.c" :1}
	]},
	{"object"[
		{"fileTokenizer.c" :3}
	]},
	{"occaecat"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :1}
	]},
	{"of"[
		{"jsonWriter.c" :1}
	]},
	{"of"[
		{"fileTokenizer.c" :3}
	]},
	{"of"[
		{"asst3hints.txt" :1}
	]},
	{"officia"[
		{"bacon1.txt" :4}
	]},
	{"on"[
		{"fileTokenizer.c" :1}
	]},
	{"once"[
		{"fileTokenizer.c" :1}
	]},
	{"one"[
		{"fileTokenizer.c" :1}
	]},
	{"only"[
		{"fileTokenizer.c" :1}
	]},
	{"open"[
		{"jsonWriter.c" :1}
	]},
	{"open"[
		{"fileTokenizer.c" :1}
	]},
	{"opening"[
		{"jsonWriter.c" :1}
	]},
	{"p"[
		{"fileTokenizer.c" :12}
	]},
	{"p0gram"[
		{"bacon0.txt" :1}
	]},
	{"pancetta"[
		{"bacon1.txt" :4},
		{"bacon0.txt" :1}
	]},
	{"pariatur"[
		{"bacon1.txt" :4}
	]},
	{"parses"[
		{"jsonWriter.c" :1}
	]},
	{"part"[
		{"jsonWriter.c" :1}
	]},
	{"part"[
		{"fileTokenizer.c" :2}
	]},
	{"passed"[
		{"fileTokenizer.c" :1}
	]},
	{"pastrami"[
		{"bacon1.txt" :4},
		{"bacon0.txt" :1}
	]},
	{"picanha"[
		{"bacon1.txt" :4}
	]},
	{"pig"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :1}
	]},
	{"please"[
		{"test1.c" :1},
		{"jsonWriter.c" :1}
	]},
	{"points"[
		{"fileTokenizer.c" :1}
	]},
	{"porchetta"[
		{"bacon1.txt" :3}
	]},
	{"pork"[
		{"bacon1.txt" :10},
		{"bacon0.txt" :2}
	]},
	{"preprocessesstring"[
		{"fileTokenizer.c" :1}
	]},
	{"prevstate"[
		{"fileTokenizer.c" :2}
	]},
	{"printf"[
		{"test1.c" :7},
		{"jsonWriter.c" :4}
	]},
	{"printf"[
		{"fileTokenizer.c" :2}
	]},
	{"printlist"[
		{"test1.c" :2}
	]},
	{"processed"[
		{"fileTokenizer.c" :1}
	]},
	{"processedlen"[
		{"fileTokenizer.c" :8}
	]},
	{"program"[
		{"fileTokenizer.c" :1}
	]},
	{"program"[
		{"asst3hints.txt" :1}
	]},
	{"proident"[
		{"bacon1.txt" :4}
	]},
	{"prosciutto"[
		{"bacon1.txt" :1},
		{"bacon0.txt" :3}
	]},
	{"put"[
		{"jsonWriter.c" :1}
	]},
	{"qui"[
		{"bacon1.txt" :1},
		{"bacon0.txt" :1}
	]},
	{"quis"[
		{"bacon1.txt" :6},
		{"bacon0.txt" :1}
	]},
	{"r"[
		{"fileTokenizer.c" :1}
	]},
	{"readdir"[
		{"asst3hints.txt" :1}
	]},
	{"record"[
		{"jsonWriter.c" :6}
	]},
	{"removefromhead"[
		{"jsonWriter.c" :1}
	]},
	{"removing"[
		{"jsonWriter.c" :1}
	]},
	{"reprehenderit"[
		{"bacon1.txt" :3},
		{"bacon0.txt" :1}
	]},
	{"res"[
		{"test1.c" :7},
		{"fileTokenizer.c" :9}
	]},
	{"responsible"[
		{"fileTokenizer.c" :1}
	]},
	{"return"[
		{"test1.c" :3},
		{"jsonWriter.c" :5}
	]},
	{"return"[
		{"fileTokenizer.c" :15}
	]},
	{"returned"[
		{"fileTokenizer.c" :1}
	]},
	{"returned"[
		{"asst3hints.txt" :1}
	]},
	{"returning"[
		{"fileTokenizer.c" :1}
	]},
	{"returns"[
		{"jsonWriter.c" :1}
	]},
	{"returns"[
		{"fileTokenizer.c" :5}
	]},
	{"returnval"[
		{"jsonWriter.c" :3}
	]},
	{"ri"[
		{"bacon0.txt" :1}
	]},
	{"ribeye"[
		{"bacon1.txt" :2}
	]},
	{"ribs"[
		{"bacon1.txt" :12},
		{"bacon0.txt" :3}
	]},
	{"room"[
		{"jsonWriter.c" :1}
	]},
	{"round"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"rump"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"s"[
		{"test1.c" :3},
		{"jsonWriter.c" :1}
	]},
	{"s"[
		{"fileTokenizer.c" :1}
	]},
	{"salami"[
		{"bacon1.txt" :4}
	]},
	{"sample"[
		{"jsonWriter.c" :1}
	]},
	{"sausage"[
		{"bacon1.txt" :6},
		{"bacon0.txt" :1}
	]},
	{"second"[
		{"cabla.txt" :1}
	]},
	{"sed"[
		{"bacon1.txt" :4}
	]},
	{"see"[
		{"jsonWriter.c" :1}
	]},
	{"see"[
		{"fileTokenizer.c" :2}
	]},
	{"shank"[
		{"bacon1.txt" :3},
		{"bacon0.txt" :1}
	]},
	{"shankle"[
		{"bacon1.txt" :8},
		{"bacon0.txt" :2}
	]},
	{"short"[
		{"bacon1.txt" :6},
		{"bacon0.txt" :2}
	]},
	{"should"[
		{"fileTokenizer.c" :3}
	]},
	{"shoulder"[
		{"bacon1.txt" :2}
	]},
	{"sint"[
		{"bacon1.txt" :6},
		{"bacon0.txt" :1}
	]},
	{"sirloin"[
		{"bacon1.txt" :3},
		{"bacon0.txt" :1}
	]},
	{"size"[
		{"fileTokenizer.c" :3}
	]},
	{"sizeof"[
		{"jsonWriter.c" :5}
	]},
	{"sizeof"[
		{"fileTokenizer.c" :4}
	]},
	{"so"[
		{"fileTokenizer.c" :1}
	]},
	{"space"[
		{"fileTokenizer.c" :5}
	]},
	{"spare"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :3}
	]},
	{"sprintf"[
		{"jsonWriter.c" :1}
	]},
	{"src"[
		{"fileTokenizer.c" :3}
	]},
	{"st"[
		{"fileTokenizer.c" :13}
	]},
	{"start"[
		{"jsonWriter.c" :4}
	]},
	{"start"[
		{"fileTokenizer.c" :4}
	]},
	{"starting"[
		{"jsonWriter.c" :1}
	]},
	{"stat"[
		{"fileTokenizer.c" :2}
	]},
	{"state"[
		{"fileTokenizer.c" :12}
	]},
	{"stateandchartest"[
		{"fileTokenizer.c" :2}
	]},
	{"staying"[
		{"fileTokenizer.c" :1}
	]},
	{"steak"[
		{"bacon1.txt" :7},
		{"bacon0.txt" :1}
	]},
	{"str"[
		{"jsonWriter.c" :4}
	]},
	{"str"[
		{"fileTokenizer.c" :9}
	]},
	{"strcat"[
		{"jsonWriter.c" :3}
	]},
	{"strcmp"[
		{"test1.c" :1}
	]},
	{"strcpy"[
		{"jsonWriter.c" :1}
	]},
	{"stream"[
		{"fileTokenizer.c" :2}
	]},
	{"string"[
		{"fileTokenizer.c" :4}
	]},
	{"strings"[
		{"fileTokenizer.c" :1}
	]},
	{"strings"[
		{"asst3hints.txt" :1}
	]},
	{"strip"[
		{"bacon1.txt" :7},
		{"bacon0.txt" :1}
	]},
	{"strlen"[
		{"jsonWriter.c" :9}
	]},
	{"strlen"[
		{"fileTokenizer.c" :1}
	]},
	{"strncpy"[
		{"fileTokenizer.c" :3}
	]},
	{"struct"[
		{"fileTokenizer.c" :2}
	]},
	{"struct"[
		{"asst3hints.txt" :1}
	]},
	{"stuff"[
		{"asst3hints.txt" :1}
	]},
	{"subdirectories"[
		{"asst3hints.txt" :1}
	]},
	{"succeeds"[
		{"fileTokenizer.c" :2}
	]},
	{"sunt"[
		{"bacon0.txt" :1}
	]},
	{"swine"[
		{"bacon1.txt" :8}
	]},
	{"switch"[
		{"fileTokenizer.c" :1}
	]},
	{"t"[
		{"jsonWriter.c" :5}
	]},
	{"t"[
		{"fileTokenizer.c" :2},
		{"bacon1.txt" :1}
	]},
	{"tail"[
		{"bacon1.txt" :9},
		{"bacon0.txt" :1}
	]},
	{"temp"[
		{"jsonWriter.c" :7}
	]},
	{"tempor"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :1}
	]},
	{"tenderloin"[
		{"bacon1.txt" :5}
	]},
	{"terminating"[
		{"fileTokenizer.c" :1}
	]},
	{"test"[
		{"fileTokenizer.c" :1},
		{"cabla.txt" :1}
	]},
	{"test"[
		{"bacon0.txt" :2}
	]},
	{"that"[
		{"jsonWriter.c" :2}
	]},
	{"that"[
		{"fileTokenizer.c" :2}
	]},
	{"the"[
		{"test1.c" :1},
		{"jsonWriter.c" :5}
	]},
	{"the"[
		{"fileTokenizer.c" :18}
	]},
	{"the"[
		{"asst3hints.txt" :1}
	]},
	{"them"[
		{"fileTokenizer.c" :1}
	]},
	{"then"[
		{"jsonWriter.c" :1}
	]},
	{"there"[
		{"fileTokenizer.c" :1}
	]},
	{"these"[
		{"fileTokenizer.c" :1}
	]},
	{"things"[
		{"fileTokenizer.c" :1}
	]},
	{"things"[
		{"asst3hints.txt" :1}
	]},
	{"this"[
		{"jsonWriter.c" :1}
	]},
	{"this"[
		{"fileTokenizer.c" :5},
		{"cabla.txt" :1}
	]},
	{"this"[
		{"bacon0.txt" :1}
	]},
	{"tip"[
		{"bacon1.txt" :8},
		{"bacon0.txt" :3}
	]},
	{"tk"[
		{"test1.c" :3},
		{"fileTokenizer.c" :25}
	]},
	{"tkcreate"[
		{"fileTokenizer.c" :2}
	]},
	{"tkdestroy"[
		{"test1.c" :1},
		{"fileTokenizer.c" :2}
	]},
	{"tkgetnexttoken"[
		{"fileTokenizer.c" :1}
	]},
	{"to"[
		{"test1.c" :2},
		{"jsonWriter.c" :5}
	]},
	{"to"[
		{"fileTokenizer.c" :8},
		{"cabla.txt" :1}
	]},
	{"to"[
		{"asst3hints.txt" :4}
	]},
	{"token"[
		{"jsonWriter.c" :8}
	]},
	{"token"[
		{"fileTokenizer.c" :14}
	]},
	{"tokenbeg"[
		{"fileTokenizer.c" :6}
	]},
	{"tokenize"[
		{"test1.c" :1},
		{"fileTokenizer.c" :1}
	]},
	{"tokenizer"[
		{"fileTokenizer.c" :2}
	]},
	{"tokenizert"[
		{"test1.c" :1},
		{"fileTokenizer.c" :10}
	]},
	{"tokenlen"[
		{"fileTokenizer.c" :9}
	]},
	{"tokensize"[
		{"jsonWriter.c" :10}
	]},
	{"tolower"[
		{"fileTokenizer.c" :1}
	]},
	{"tongue"[
		{"bacon1.txt" :1},
		{"bacon0.txt" :2}
	]},
	{"track"[
		{"asst3hints.txt" :1}
	]},
	{"trailing"[
		{"jsonWriter.c" :10}
	]},
	{"trailing"[
		{"cabla.txt" :1}
	]},
	{"tri"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :3}
	]},
	{"try"[
		{"fileTokenizer.c" :2}
	]},
	{"trying"[
		{"test1.c" :1}
	]},
	{"turducken"[
		{"bacon1.txt" :6},
		{"bacon0.txt" :1}
	]},
	{"turkey"[
		{"bacon1.txt" :3}
	]},
	{"type"[
		{"fileTokenizer.c" :1}
	]},
	{"uh"[
		{"bacon0.txt" :1}
	]},
	{"ullamco"[
		{"bacon1.txt" :5}
	]},
	{"until"[
		{"fileTokenizer.c" :1}
	]},
	{"up"[
		{"jsonWriter.c" :1}
	]},
	{"use"[
		{"jsonWriter.c" :1}
	]},
	{"ut"[
		{"bacon1.txt" :14},
		{"bacon0.txt" :4}
	]},
	{"val"[
		{"test1.c" :1}
	]},
	{"valid"[
		{"test1.c" :1},
		{"jsonWriter.c" :1}
	]},
	{"velit"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :3}
	]},
	{"veniam"[
		{"bacon1.txt" :3},
		{"bacon0.txt" :1}
	]},
	{"venison"[
		{"bacon1.txt" :5},
		{"bacon0.txt" :2}
	]},
	{"void"[
		{"fileTokenizer.c" :1}
	]},
	{"voluptate"[
		{"bacon1.txt" :2},
		{"bacon0.txt" :1}
	]},
	{"w"[
		{"jsonWriter.c" :1}
	]},
	{"we"[
		{"fileTokenizer.c" :3}
	]},
	{"what"[
		{"fileTokenizer.c" :3}
	]},
	{"which"[
		{"fileTokenizer.c" :1}
	]},
	{"while"[
		{"test1.c" :1},
		{"jsonWriter.c" :1}
	]},
	{"while"[
		{"fileTokenizer.c" :1}
	]},
	{"white"[
		{"fileTokenizer.c" :1}
	]},
	{"word"[
		{"fileTokenizer.c" :5}
	]},
	{"write"[
		{"jsonWriter.c" :1}
	]},
	{"writer"[
		{"asst3hints.txt" :1}
	]},
	{"writes"[
		{"jsonWriter.c" :1}
	]},
	{"writes"[
		{"asst3hints.txt" :1}
	]},
	{"writing"[
		{"jsonWriter.c" :1}
	]},
	{"written"[
		{"jsonWriter.c" :1}
	]},
	{"you"[
		{"jsonWriter.c" :1}
	]},
	{"you"[
		{"fileTokenizer.c" :1}
	]},
	{"your"[
		{"fileTokenizer.c" :1}
	]},
	{"zeta"[
		{"cabla.txt" :1}
	]}
]}